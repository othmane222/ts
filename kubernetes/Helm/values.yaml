# values.yaml

# Use the CPU image unless you have a multi-GPU node available.
torchserve_image: pytorch/torchserve:latest

# All the settings for the TorchServe application itself.
torchserve:
  management_port: 8081
  inference_port: 8080
  pvd_mount: /home/model-server/shared/
  n_gpu: 0
  n_cpu: 1
  memory_limit: 6Gi
  memory_request: 2Gi

# Settings for the Kubernetes Deployment object.
deployment:
  replicas: 2

# --- NEW SECTION FOR YOUR PVC ---
# Configuration for the PersistentVolumeClaim
pvc:
  # The name for the PVC resource that will be created.
  name: efs-claim
  # The StorageClass to use (e.g., "local-path", or a proper RWX class like "nfs-csi").
  storageClassName: "local-path" # <-- CHANGE THIS when you have RWX storage
  # The access modes for the volume.
  accessModes:
    - ReadWriteOnce # <-- CHANGE THIS to ReadWriteMany for multi-node scaling
  # The amount of storage to request.
  storageRequest: 10Gi

# --- NEW SECTION FOR YOUR CONFIGMAP ---
# Configuration for the TorchServe ConfigMap
configmap:
  # The name for the ConfigMap resource.
  name: torchserve-configmap
  # The content of the config.properties file.
  properties: |
    inference_address=http://0.0.0.0:8080
    management_address=http://0.0.0.0:8081
    log_location=/home/model-server/logs
    log_level=DEBUG

# --- THIS SECTION IS NOW REDUNDANT IF YOU USE THE PVC SECTION ABOVE ---
# You can remove it to avoid confusion.
persistentVolume:
  name: efs-claim 