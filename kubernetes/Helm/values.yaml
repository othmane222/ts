# A clean values.yaml for TorchServe, designed to fix the Helm template error.

# Use the CPU image unless you have a multi-GPU node available.
torchserve_image: pytorch/torchserve:latest

# This namespace key in values.yaml is often ignored, but we'll leave it.
# The command line "-n torchserve" is what actually matters.
namespace: torchserve

# All the settings for the TorchServe application itself.
torchserve:
  management_port: 8081
  inference_port: 8080
  metrics_port: 8082
  grpc_inference_port: 7070
  pvd_mount: /home/model-server/shared/
  
  # --- ADJUST THESE RESOURCES TO MATCH YOUR CLUSTER ---
  n_gpu: 0         # Set to 0 for CPU-only nodes
  n_cpu: 1       # Request 1 CPU core
  memory_limit: 6Gi
  memory_request: 2Gi # Request less memory to ensure it can be scheduled
  # ----------------------------------------------------
  
# Settings for the Kubernetes Deployment object.
deployment:
  replicas: 1 # Start with 1 replica for testing

# --- THIS IS THE CRITICAL SECTION TO FIX THE ERROR ---
# The template error ".Values.persistentVolume.name" dictates this exact structure.
persistentVolume:
  # The name MUST match the PersistentVolumeClaim you created earlier.
  name: efs-claim
# ----------------------------------------------------